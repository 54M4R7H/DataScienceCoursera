## Deep Learning - Coursera
**Specialization** provided by DeepLearning.ai

### Course 5 - Sequence Models

- Week 1 - Recurrent Neural Networks
  - Why sequence models
  - Notation
  - Recurrent Neural Network Model
  - Backpropagation through time
  - Different types of RNNs
  - Language model and sequence generation
  - Sampling novel sequences
  - Vanishing gradients with RNNs
  - Gated Recurrent Unit (GRU)
  - Long Short Term Memory (LSTM)
  - Bidirectional RNN
  - Deep RNNs
  - Programming Assignment: [Recurrent Neural Network: step by step](https://github.com/bhunkeler/DataScienceCoursera/blob/master/Deep%20Learning%20-%20Deeplearning.ai/005_Sequence_Models/Week%201/Programming%20Assignment/Building%20a%20Recurrent%20Neural%20Network%20-%20Step%20by%20Step/Building%2Ba%2BRecurrent%2BNeural%2BNetwork%2B-%2BStep%2Bby%2BStep%2B-%2Bv3.ipynb)
  - Programming Assignment: [Dinosaur Island - Character-Level Language Modeling](https://github.com/bhunkeler/DataScienceCoursera/blob/master/Deep%20Learning%20-%20Deeplearning.ai/005_Sequence_Models/Week%201/Programming%20Assignment/Dinosaur%20Island%20--%20Character-level%20language%20model/Dinosaurus%2BIsland%2B--%2BCharacter%2Blevel%2Blanguage%2Bmodel%2Bfinal%2B-%2Bv3.ipynb)
  - Programming Assignment: [Jazz improvisation with LSTM](https://github.com/bhunkeler/DataScienceCoursera/blob/master/Deep%20Learning%20-%20Deeplearning.ai/005_Sequence_Models/Week%201/Programming%20Assignment/Jazz%20improvisation%20with%20LSTM/Improvise%2Ba%2BJazz%2BSolo%2Bwith%2Ban%2BLSTM%2BNetwork%2B-%2Bv1.ipynb)

- Week 2 - Natural Language Processing & Word Embeddings
  - Word Representation
  - Using word embeddings
  - Properties of word embeddings
  - Embedding matrix
  - Learning word embeddings
  - Word2Vec
  - Negative Sampling
  - GloVe word vectors
  - Sentiment Classification
  - Debiasing word embeddings
  - Programming Assignment: [Operations on word vectors - Debiasing](https://github.com/bhunkeler/DataScienceCoursera/blob/master/Deep%20Learning%20-%20Deeplearning.ai/005_Sequence_Models/Week%202/Programming%20Assignment/Operations_on_word_vectors/Operations%2Bon%2Bword%2Bvectors%2B-%2Bv2.ipynb)
  - Programming Assignment: [Emojify](https://github.com/bhunkeler/DataScienceCoursera/blob/master/Deep%20Learning%20-%20Deeplearning.ai/005_Sequence_Models/Week%202/Programming%20Assignment/Emojify/Emojify%2B-%2Bv2.ipynb)
  
- Week 3 - Sequence models & Attention mechanism
  - Basic Models
  - Picking the most likely sentence
  - Beam Search
  - Refinements to Beam Search
  - Error analysis in beam search
  - Bleu Score (optional)
  - Attention Model Intuition
  - Attention Model
  - Speech recognition
  - Trigger Word Detection
  - Conclusion and thank you
  - Programming Assignment: [Neural Machine Translation with Attention](https://github.com/bhunkeler/DataScienceCoursera/blob/master/Deep%20Learning%20-%20Deeplearning.ai/005_Sequence_Models/Week%203/Programming%20Assignment/Machine%20Translation/Neural%2Bmachine%2Btranslation%2Bwith%2Battention%2B-%2Bv3.ipynb)
  - Programming Assignment: [Trigger word detection](https://github.com/bhunkeler/DataScienceCoursera/blob/master/Deep%20Learning%20-%20Deeplearning.ai/005_Sequence_Models/Week%203/Programming%20Assignment/Trigger%20Word%20Detection/Trigger%2Bword%2Bdetection%2B-%2Bv1.ipynb)

